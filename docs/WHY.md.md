***√âtape 1 : L'√âtat Stable (La Paix)***



***Ta table contient les donn√©es de 11h00.***



***Sur S3 : Tu as un fichier data\_1100.parquet.***



***Dans le JSON (v1.json) : Il est √©crit files: \["data\_1100.parquet"].***



***R√©sultat du SELECT : Tout va bien, on voit les donn√©es de 11h.***



***√âtape 2 : Le Duel des Jobs (Le Chaos)***



***Deux jobs se lancent en m√™me temps (ou se chevauchent).***



***Le Job "Lent" (Batch de 12h00) :***



***Il √©crit data\_1200.parquet sur S3.***



***Il prend du temps √† cause du r√©seau...***



***Le Job "Rapide" (Batch de 13h00) :***



***Il √©crit data\_1300.parquet sur S3.***



***Il finit avant le job de 12h.***



***Il met √† jour le catalogue et cr√©e le v2.json.***



***Contenu du v2.json : files: \["data\_1100.parquet", "data\_1300.parquet"].***



***√âtape 3 : Le Conflit Silencieux (Le Crime)***



***Le Job de 12h00 essaie enfin de valider son travail.***



***Il voit que le v2.json existe d√©j√†.***



***Le syst√®me (Iceberg/Delta) lui dit : "Erreur de conflit ! Quelqu'un a √©crit avant toi !".***



***L'√©chec technique : Le Job de 12h s'arr√™te. Il ne met jamais √† jour le JSON.***



***L'orchestrateur (na√Øf) : Il voit une erreur, il fait un "Retry" ou il passe au suivant.***



***√âtape 4 : Le "Trou" est cr√©√©***



***Si tu fais un SELECT maintenant, que se passe-t-il ?***



***Le moteur SQL lit le v2.json.***



***Il voit les donn√©es de 11h et de 13h.***



***Le trou : Les donn√©es de 12h sont physiquement sur S3 (le fichier data\_1200.parquet est bien l√†), mais elles sont invisibles pour le monde entier.***



***√âtape 5 : L'intervention de la "Sentinelle" (Ton Projet)***



***C'est ici que ton code de Batch Tracker entre en sc√®ne. Il ne fait pas de SQL, il fait de l'inspection de fichiers.***



***Le script de ton projet fait ceci :***



***Scan Physique (S3) :***

***files\_on\_disk = \["data\_1100.parquet", "data\_1200.parquet", "data\_1300.parquet"]***



***Scan Logique (JSON) :***

***files\_in\_catalog = \["data\_1100.parquet", "data\_1300.parquet"]***



***La Comparaison "Nasty" :***



***code***

***Python***

***download***

***content\_copy***

***expand\_less***

***ghost\_files = set(files\_on\_disk) - set(files\_in\_catalog)***

***# R√©sultat : \["data\_1200.parquet"]***



***Le verdict de ton outil :***



***üö® ALERTE : J'ai trouv√© un fichier orphelin (data\_1200.parquet). Ce fichier contient des donn√©es qui devraient √™tre dans la table mais qui n'y sont pas. Votre pipeline a "saut√©" le batch de 12h00 √† cause d'un conflit de m√©tadonn√©es.***



## 

